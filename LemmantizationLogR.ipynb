{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review =[]\n",
    "for line in open('../movie-sentiment-analysis/aclImdb/movie_data/full_train.txt','r',encoding='utf-8'):\n",
    "    train_review.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review=[]\n",
    "for line in open('../movie-sentiment-analysis/aclImdb/movie_data/full_test.txt','r',encoding='utf-8'):\n",
    "    test_review.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEANING && PREPROCESS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_space = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "with_space = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "def cleaningandprocessing(reviews):\n",
    "    reviews = [no_space.sub(\"\",line.lower()) for line in reviews]\n",
    "    reviews = [with_space.sub(\" \",line) for line in reviews]\n",
    "    return reviews\n",
    "clean_train_reviews = cleaningandprocessing(train_review)\n",
    "clean_test_reviews = cleaningandprocessing(test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\srija\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\srija\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def get_lemmatized_text(corpus):\n",
    "    nltk.download('wordnet')\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "lemmatized_reviews_train = get_lemmatized_text(clean_train_reviews)\n",
    "lemmatized_reviews_test = get_lemmatized_text(clean_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(lemmatized_reviews_train)\n",
    "X_train = cv.transform(lemmatized_reviews_train)\n",
    "X_test = cv.transform(lemmatized_reviews_test)\n",
    "target = [1 if i <12500 else 0 for i in range(25000)]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, target, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For:  0.01\n",
      "\n",
      "\n",
      "0.8463\n",
      "\n",
      "\n",
      "[[8339 1623]\n",
      " [1451 8587]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.84      0.84      9962\n",
      "          1       0.84      0.86      0.85     10038\n",
      "\n",
      "avg / total       0.85      0.85      0.85     20000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For:  0.05\n",
      "\n",
      "\n",
      "0.8541\n",
      "\n",
      "\n",
      "[[8422 1540]\n",
      " [1378 8660]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      9962\n",
      "          1       0.85      0.86      0.86     10038\n",
      "\n",
      "avg / total       0.85      0.85      0.85     20000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For:  0.1\n",
      "\n",
      "\n",
      "0.85445\n",
      "\n",
      "\n",
      "[[8449 1513]\n",
      " [1398 8640]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      9962\n",
      "          1       0.85      0.86      0.86     10038\n",
      "\n",
      "avg / total       0.85      0.85      0.85     20000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For:  0.25\n",
      "\n",
      "\n",
      "0.8539\n",
      "\n",
      "\n",
      "[[8438 1524]\n",
      " [1398 8640]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      9962\n",
      "          1       0.85      0.86      0.86     10038\n",
      "\n",
      "avg / total       0.85      0.85      0.85     20000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For:  0.5\n",
      "\n",
      "\n",
      "0.85285\n",
      "\n",
      "\n",
      "[[8435 1527]\n",
      " [1416 8622]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      9962\n",
      "          1       0.85      0.86      0.85     10038\n",
      "\n",
      "avg / total       0.85      0.85      0.85     20000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For:  1\n",
      "\n",
      "\n",
      "0.85015\n",
      "\n",
      "\n",
      "[[8407 1555]\n",
      " [1442 8596]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.84      0.85      9962\n",
      "          1       0.85      0.86      0.85     10038\n",
      "\n",
      "avg / total       0.85      0.85      0.85     20000\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01,0.05,0.1,0.25,0.5,1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(x_train, y_train)\n",
    "    print(\"For: \", c)\n",
    "    print(\"\\n\")\n",
    "    print(accuracy_score(y_test, lr.predict(x_test)))\n",
    "    print(\"\\n\")\n",
    "    print(confusion_matrix(y_test, lr.predict(x_test)))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test, lr.predict(x_test)))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AT C= 0.1  ACCURACY SCORE IS 85.445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is:  0.87824\n",
      "\n",
      "\n",
      "Confusion matrix is:  [[10945  1555]\n",
      " [ 1489 11011]]\n",
      "\n",
      "\n",
      "Classification matrix is:               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88     12500\n",
      "          1       0.88      0.88      0.88     12500\n",
      "\n",
      "avg / total       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.1)\n",
    "final_model.fit(X_train, target)\n",
    "predictions1 = final_model.predict(X_test)\n",
    "print(\"Accuracy score is: \",accuracy_score(target,predictions1))\n",
    "print(\"\\n\")\n",
    "print(\"Confusion matrix is: \", confusion_matrix(target, predictions1))\n",
    "print(\"\\n\")\n",
    "print(\"Classification matrix is: \",classification_report(target, predictions1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL MODEL ACCURACY IS 87.78"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
